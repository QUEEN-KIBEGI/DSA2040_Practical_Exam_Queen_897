{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85eed855",
   "metadata": {},
   "source": [
    "# Task 1: Data Preprocessing and Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b0e68c",
   "metadata": {},
   "source": [
    "## 1.Load the dataset in Python using pandas or scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61769236",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Configure visualization style\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "def load_and_preprocess():\n",
    "    \"\"\"Load and preprocess the Iris dataset\"\"\"\n",
    "    # 1. Load dataset\n",
    "    iris = load_iris()\n",
    "    df = pd.DataFrame(data=np.c_[iris['data'], iris['target']],\n",
    "                     columns=iris['feature_names'] + ['target'])\n",
    "    \n",
    "    # Map target to species names\n",
    "    df['species'] = df['target'].map({0: 'setosa', 1: 'versicolor', 2: 'virginica'})\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcee557f",
   "metadata": {},
   "source": [
    "## 2.Preprocess:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f8c577e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_load_and_preprocess():\n",
    "    \"\"\"Load and preprocess the Iris dataset\"\"\"\n",
    "    # 1. Load dataset\n",
    "    iris = load_iris()\n",
    "    df = pd.DataFrame(data=np.c_[iris['data'], iris['target']],\n",
    "                     columns=iris['feature_names'] + ['target'])\n",
    "    \n",
    "    # Map target to species names\n",
    "    df['species'] = df['target'].map({0: 'setosa', 1: 'versicolor', 2: 'virginica'})\n",
    "    \n",
    "    # 2. Check for missing values\n",
    "    print(\"\\nMissing values check:\")\n",
    "    print(df.isnull().sum())\n",
    "    \n",
    "    # 3. Normalize features (excluding target)\n",
    "    scaler = MinMaxScaler()\n",
    "    features = iris['feature_names']\n",
    "    df[features] = scaler.fit_transform(df[features])\n",
    "    \n",
    "    return df, features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c357e4",
   "metadata": {},
   "source": [
    "## 3. Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2880250a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== IRIS DATA PROCESSING PIPELINE ===\n",
      "\n",
      "First 5 rows:\n",
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0           0.222222          0.625000           0.067797          0.041667   \n",
      "1           0.166667          0.416667           0.067797          0.041667   \n",
      "2           0.111111          0.500000           0.050847          0.041667   \n",
      "3           0.083333          0.458333           0.084746          0.041667   \n",
      "4           0.194444          0.666667           0.067797          0.041667   \n",
      "\n",
      "   target species  \n",
      "0     0.0  setosa  \n",
      "1     0.0  setosa  \n",
      "2     0.0  setosa  \n",
      "3     0.0  setosa  \n",
      "4     0.0  setosa  \n",
      "\n",
      "Summary statistics:\n",
      "       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
      "count         150.000000        150.000000         150.000000   \n",
      "mean            0.428704          0.440556           0.467458   \n",
      "std             0.230018          0.181611           0.299203   \n",
      "min             0.000000          0.000000           0.000000   \n",
      "25%             0.222222          0.333333           0.101695   \n",
      "50%             0.416667          0.416667           0.567797   \n",
      "75%             0.583333          0.541667           0.694915   \n",
      "max             1.000000          1.000000           1.000000   \n",
      "\n",
      "       petal width (cm)  \n",
      "count        150.000000  \n",
      "mean           0.458056  \n",
      "std            0.317599  \n",
      "min            0.000000  \n",
      "25%            0.083333  \n",
      "50%            0.500000  \n",
      "75%            0.708333  \n",
      "max            1.000000  \n",
      "\n",
      "Generating pairplot...\n",
      "Generating correlation heatmap...\n",
      "Generating boxplots...\n",
      "\n",
      "Train/test split results:\n",
      "Training samples: 120\n",
      "Test samples: 30\n",
      "Feature names: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "\n",
      "Processing complete. Files created:\n",
      "- iris_pairplot.png\n",
      "- iris_correlation.png\n",
      "- iris_boxplots.png\n",
      "- processed_iris.csv\n",
      "\n",
      "=== PIPELINE COMPLETED SUCCESSFULLY ===\n"
     ]
    }
   ],
   "source": [
    "# Complete Data Processing Pipeline\n",
    "def explore_data_clean(df, features):\n",
    "    \"\"\"Perform data exploration and visualization\"\"\"\n",
    "    # 1. Summary statistics\n",
    "    print(\"\\nSummary statistics:\")\n",
    "    print(df[features].describe())\n",
    "    \n",
    "    # 2. Pairplot\n",
    "    print(\"\\nGenerating pairplot...\")\n",
    "    sns.pairplot(df, hue='species', palette='viridis')\n",
    "    plt.savefig('iris_pairplot.png', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # 3. Correlation heatmap\n",
    "    print(\"Generating correlation heatmap...\")\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.heatmap(df[features].corr(), annot=True, cmap='coolwarm', center=0)\n",
    "    plt.title('Feature Correlation Heatmap')\n",
    "    plt.savefig('iris_correlation.png', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # 4. Outlier detection with boxplots\n",
    "    print(\"Generating boxplots...\")\n",
    "    plt.figure(figsize=(12,6))\n",
    "    df_melted = df.melt(id_vars='species', value_vars=features)\n",
    "    sns.boxplot(x='variable', y='value', hue='species', data=df_melted, palette='Set2')\n",
    "    plt.title('Feature Distribution by Species')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('iris_boxplots.png', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "def split_data_clean(df, features, test_size=0.2, random_state=42):\n",
    "    \"\"\"Split data into train/test sets\"\"\"\n",
    "    X = df[features]\n",
    "    y = df['target']\n",
    "    return train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "# Execute the complete pipeline\n",
    "print(\"=== IRIS DATA PROCESSING PIPELINE ===\")\n",
    "\n",
    "# 1. Load and preprocess (if not already done)\n",
    "if 'df' not in locals() or 'features' not in locals():\n",
    "    df, features = complete_load_and_preprocess()\n",
    "\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# 2. Explore data\n",
    "explore_data_clean(df, features)\n",
    "\n",
    "#Function to split data\n",
    "# 3. Split data\n",
    "X_train, X_test, y_train, y_test = split_data_clean(df, features)\n",
    "print(\"\\nTrain/test split results:\")\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")\n",
    "print(f\"Feature names: {features}\")\n",
    "\n",
    "# Save processed data\n",
    "df.to_csv('processed_iris.csv', index=False)\n",
    "print(\"\\nProcessing complete. Files created:\")\n",
    "print(\"- iris_pairplot.png\")\n",
    "print(\"- iris_correlation.png\") \n",
    "print(\"- iris_boxplots.png\")\n",
    "print(\"- processed_iris.csv\")\n",
    "\n",
    "print(\"\\n=== PIPELINE COMPLETED SUCCESSFULLY ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2dac0f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_data():\n",
    "    \"\"\"Generate Iris-like synthetic data\"\"\"\n",
    "    np.random.seed(42)\n",
    "    n_samples = 150\n",
    "    features = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
    "    \n",
    "    # Create 3 clusters with Gaussian distributions\n",
    "    cluster1 = np.random.normal(loc=[5.0, 3.4, 1.5, 0.2], scale=[0.4, 0.3, 0.2, 0.1], size=(n_samples//3, 4))\n",
    "    cluster2 = np.random.normal(loc=[6.0, 2.8, 4.5, 1.3], scale=[0.5, 0.3, 0.3, 0.2], size=(n_samples//3, 4))\n",
    "    cluster3 = np.random.normal(loc=[6.7, 3.0, 5.7, 2.0], scale=[0.4, 0.3, 0.4, 0.3], size=(n_samples//3, 4))\n",
    "    \n",
    "    data = np.vstack([cluster1, cluster2, cluster3])\n",
    "    target = np.array([0]*50 + [1]*50 + [2]*50)\n",
    "    \n",
    "    df = pd.DataFrame(data, columns=features)\n",
    "    df['target'] = target\n",
    "    df['species'] = df['target'].map({0: 'setosa', 1: 'versicolor', 2: 'virginica'})\n",
    "    \n",
    "    return df, features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
